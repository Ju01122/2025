import io
import pandas as pd
import numpy as np
import streamlit as st
pip install scikit-learn
from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# =============================
# í˜ì´ì§€ ì„¤ì •
# =============================
st.set_page_config(page_title="ìŠ¤ë§ˆíŠ¸íŒœ ìˆ˜í™•ëŸ‰ ì˜ˆì¸¡", page_icon="ğŸŒ±", layout="wide")
st.title("ğŸŒ± ìŠ¤ë§ˆíŠ¸íŒœ ìˆ˜í™•ëŸ‰ ì˜ˆì¸¡ ì›¹ì•±")
st.write("í™˜ê²½ ë°ì´í„°(ì˜¨ë„/ìŠµë„/COâ‚‚/ì¼ì‚¬ëŸ‰ ë“±)ì™€ ìƒìœ¡/ìˆ˜í™•ëŸ‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ì˜ˆì¸¡ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.")

# =============================
# ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë“œ & ì˜µì…˜
# =============================
st.sidebar.header("1) ë°ì´í„° ì—…ë¡œë“œ")
env_file = st.sidebar.file_uploader("ì‹œì„¤ì›ì˜ˆ_ì¼ê¸°ì¤€_í™˜ê²½ì •ë³´ ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx", "xls"])
growth_file = st.sidebar.file_uploader("ì‹œì„¤ì›ì˜ˆ_ìƒìœ¡ì •ë³´/ìˆ˜í™•ëŸ‰ ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx", "xls"])

st.sidebar.header("2) ì „ì²˜ë¦¬ ì˜µì…˜")
rm_desc_rows = st.sidebar.checkbox("í™˜ê²½ ë°ì´í„° ìƒë‹¨ ì„¤ëª…í–‰ 2ì¤„ ì œê±°(ê¶Œì¥)", value=True, help="ì œê³µëœ í‘œì¤€ í™˜ê²½íŒŒì¼ì— ì„¤ëª…í–‰ì´ 2ì¤„ í¬í•¨ëœ ê²½ìš° ì‚¬ìš©")

st.sidebar.header("3) ëª¨ë¸ ì˜µì…˜")
model_name = st.sidebar.selectbox("ëª¨ë¸ ì„ íƒ", ["LinearRegression", "RandomForest"], index=1)
cv_splits = st.sidebar.slider("TimeSeries CV ë¶„í•  ìˆ˜", 3, 10, 5)

test_ratio = st.sidebar.slider("ê²€ì¦ìš© ë¹„ìœ¨ (ìµœê·¼ ê¸°ê°„)", 0.1, 0.4, 0.2, step=0.05)

# =============================
# ìœ í‹¸ í•¨ìˆ˜
# =============================
DATE_CANDIDATES = ["ìˆ˜ì§‘ì¼", "ë‚ ì§œ", "Date", "date", "ê¸°ì¤€ì¼", "ì¸¡ì •ì¼"]

def detect_date_col(df: pd.DataFrame) -> str | None:
    for c in df.columns:
        if any(k in str(c) for k in DATE_CANDIDATES):
            return c
    # fallback: try first datetime-like
    for c in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[c]):
            return c
    return None


def clean_environment_df(df_raw: pd.DataFrame, remove_top_two: bool = True) -> pd.DataFrame:
    df = df_raw.copy()
    if remove_top_two and len(df) > 2:
        df = df.iloc[2:].copy()
        # ì œê³µëœ í‘œì¤€ íŒŒì¼ì˜ ì˜ˆìƒ ì»¬ëŸ¼ëª… ì¬ì •ì˜ (ì—†ìœ¼ë©´ ê¸°ì¡´ ìœ ì§€)
        expected = [
            "ìˆ˜ì§‘ì¼", "ë‚´ë¶€CO2", "ë‚´ë¶€ì´ìŠ¬ì ì˜¨ë„", "ë‚´ë¶€ìŠµë„", "ì–‘ì•¡ì§€ìŠµ", "ì™¸ë¶€ì¼ì‚¬ëŸ‰", "ì™¸ë¶€ì˜¨ë„",
            "ë‚´ë¶€ì˜¨ë„", "í† ì–‘ì˜¨ë„", "ì™¸ë¶€í’í–¥", "ì™¸ë¶€í’ì†", "ì ì‚°ì˜¨ë„", "24ì‹œê°„í‰ê· ì˜¨ë„"
        ]
        if df.shape[1] >= len(expected):
            df.columns = expected + [f"col_{i}" for i in range(len(expected), df.shape[1])]
    # ë‚ ì§œ/ìˆ«ì ë³€í™˜
    date_col = detect_date_col(df)
    if date_col is None:
        st.warning("í™˜ê²½ ë°ì´í„°ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'ìˆ˜ì§‘ì¼/ë‚ ì§œ' ë“±ì˜ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
        df = df.dropna(subset=[date_col])
        df = df.sort_values(date_col)
        df = df.rename(columns={date_col: "ë‚ ì§œ"})
    # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ ì‹œë„
    for c in df.columns:
        if c == "ë‚ ì§œ":
            continue
        df[c] = pd.to_numeric(df[c], errors="coerce")
    # ì¤‘ë³µ ë‚ ì§œ í‰ê·  ì²˜ë¦¬
    df = df.groupby("ë‚ ì§œ", as_index=False).mean(numeric_only=True)
    return df


def clean_growth_df(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()
    # ë‚ ì§œ ì»¬ëŸ¼ ê°ì§€ ë° ë³€í™˜
    date_col = detect_date_col(df)
    if date_col is None:
        st.warning("ìƒìœ¡/ìˆ˜í™•ëŸ‰ ë°ì´í„°ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'ìˆ˜ì§‘ì¼/ë‚ ì§œ' ë“±ì˜ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
        df = df.dropna(subset=[date_col])
        df = df.sort_values(date_col)
        df = df.rename(columns={date_col: "ë‚ ì§œ"})
    # ìˆ«ìí˜• ë³€í™˜
    for c in df.columns:
        if c == "ë‚ ì§œ":
            continue
        df[c] = pd.to_numeric(df[c], errors="coerce")
    # ì¤‘ë³µ ë‚ ì§œ ì§‘ê³„: í‰ê· (ë˜ëŠ” í•©ê³„ê°€ ë” ë§ë‹¤ë©´ ì•„ë˜ë¥¼ sumìœ¼ë¡œ ë³€ê²½)
    df = df.groupby("ë‚ ì§œ", as_index=False).mean(numeric_only=True)
    return df


def add_time_features(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["year"] = out["ë‚ ì§œ"].dt.year
    out["month"] = out["ë‚ ì§œ"].dt.month
    out["day"] = out["ë‚ ì§œ"].dt.day
    out["dow"] = out["ë‚ ì§œ"].dt.dayofweek
    return out


def add_rolling_features(df: pd.DataFrame, feature_cols: list[str], windows=(3, 7)) -> pd.DataFrame:
    out = df.copy()
    for w in windows:
        for c in feature_cols:
            out[f"{c}_roll{w}"] = out[c].rolling(window=w, min_periods=1).mean()
    return out

# =============================
# ë°ì´í„° ë¡œë”© & ì „ì²˜ë¦¬
# =============================
if env_file is not None and growth_file is not None:
    try:
        env_df_raw = pd.read_excel(env_file)
        growth_df_raw = pd.read_excel(growth_file)
    except Exception as e:
        st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

    env_df = clean_environment_df(env_df_raw, remove_top_two=rm_desc_rows)
    growth_df = clean_growth_df(growth_df_raw)

    st.subheader("ğŸ“„ ë¯¸ë¦¬ë³´ê¸°")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**í™˜ê²½ ë°ì´í„° (ì •ë¦¬ í›„ ìƒìœ„ 5í–‰)**")
        st.dataframe(env_df.head())
    with c2:
        st.markdown("**ìƒìœ¡/ìˆ˜í™•ëŸ‰ ë°ì´í„° (ì •ë¦¬ í›„ ìƒìœ„ 5í–‰)**")
        st.dataframe(growth_df.head())

    # íƒ€ê¹ƒ ì„ íƒ (ìƒìœ¡/ìˆ˜í™•ëŸ‰ ë°ì´í„°ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì¤‘ ì„ íƒ)
    numeric_cols_growth = [c for c in growth_df.columns if c != "ë‚ ì§œ" and pd.api.types.is_numeric_dtype(growth_df[c])]
    if not numeric_cols_growth:
        st.error("ìƒìœ¡/ìˆ˜í™•ëŸ‰ ë°ì´í„°ì— ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ ì»¬ëŸ¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    target_col = st.selectbox("ì˜ˆì¸¡í•  íƒ€ê¹ƒ(ìˆ˜í™•ëŸ‰/ìƒìœ¡ì§€í‘œ) ì»¬ëŸ¼ ì„ íƒ", numeric_cols_growth)

    # í”¼ì²˜ í›„ë³´ (í™˜ê²½ ë°ì´í„°ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼)
    numeric_cols_env = [c for c in env_df.columns if c != "ë‚ ì§œ" and pd.api.types.is_numeric_dtype(env_df[c])]
    default_features = [c for c in numeric_cols_env if c in ["ë‚´ë¶€ì˜¨ë„", "ë‚´ë¶€ìŠµë„", "ë‚´ë¶€CO2", "ì™¸ë¶€ì¼ì‚¬ëŸ‰", "ì™¸ë¶€ì˜¨ë„", "í† ì–‘ì˜¨ë„", "24ì‹œê°„í‰ê· ì˜¨ë„"]]
    if not default_features:
        default_features = numeric_cols_env[: min(6, len(numeric_cols_env))]

    selected_features = st.multiselect(
        "í™˜ê²½ í”¼ì²˜ ì„ íƒ (ì˜ˆ: ë‚´ë¶€ì˜¨ë„/ë‚´ë¶€ìŠµë„/CO2/ì¼ì‚¬ëŸ‰ ë“±)",
        numeric_cols_env,
        default=default_features,
    )

    if not selected_features:
        st.warning("ìµœì†Œ 1ê°œ ì´ìƒì˜ í™˜ê²½ í”¼ì²˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()

    # ë³‘í•© ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    merged = pd.merge_asof(
        left=growth_df.sort_values("ë‚ ì§œ"),
        right=env_df.sort_values("ë‚ ì§œ"),
        on="ë‚ ì§œ",
        direction="backward",
    )

    # ì‹œê³„ì—´ íŒŒìƒì¹˜ ì¶”ê°€
    merged = add_time_features(merged)
    merged = add_rolling_features(merged, selected_features, windows=(3, 7))

    # ëª¨ë¸ ì…ë ¥/íƒ€ê¹ƒ êµ¬ì„±
    feature_cols = selected_features + [f"{c}_roll3" for c in selected_features] + [f"{c}_roll7" for c in selected_features] + ["year", "month", "day", "dow"]
    X = merged[feature_cols].copy()
    y = merged[target_col].copy()

    # ëˆ„ë½ì¹˜ ì²˜ë¦¬
    # (TimeSeriesSplitì„ ì“°ë¯€ë¡œ ê°„ë‹¨íˆ í‰ê· ëŒ€ì¹˜ + ìŠ¤ì¼€ì¼ë§)
    numeric_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
    ])

    preprocessor = ColumnTransformer(
        transformers=[("num", numeric_transformer, feature_cols)],
        remainder="drop",
    )

    if model_name == "LinearRegression":
        model = LinearRegression()
    else:
        model = RandomForestRegressor(n_estimators=400, random_state=42)

    pipe = Pipeline(steps=[("prep", preprocessor), ("model", model)])

    # í•™ìŠµ/ê²€ì¦ ë¶„í•  (ìµœê·¼ test_ratio ë¹„ìœ¨ì„ í…ŒìŠ¤íŠ¸ë¡œ ì‚¬ìš©)
    n = len(X)
    test_size = max(1, int(n * test_ratio))
    train_X, test_X = X.iloc[:-test_size], X.iloc[-test_size:]
    train_y, test_y = y.iloc[:-test_size], y.iloc[-test_size:]

    # êµì°¨ê²€ì¦ (ì‹œê³„ì—´)
    tscv = TimeSeriesSplit(n_splits=cv_splits)
    try:
        cv_scores = cross_val_score(pipe, X, y, cv=tscv, scoring="r2")
        cv_msg = f"TimeSeries CV RÂ²: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}"
    except Exception as e:
        cv_msg = f"êµì°¨ê²€ì¦ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"

    # í•™ìŠµ ë° í‰ê°€
    pipe.fit(train_X, train_y)
    pred_train = pipe.predict(train_X)
    pred_test = pipe.predict(test_X)

    r2_tr = r2_score(train_y, pred_train)
    r2_te = r2_score(test_y, pred_test)
    mae_te = mean_absolute_error(test_y, pred_test)
    rmse_te = mean_squared_error(test_y, pred_test, squared=False)

    st.subheader("ğŸ“ˆ í•™ìŠµ ê²°ê³¼")
    st.write(cv_msg)
    c1, c2, c3 = st.columns(3)
    c1.metric("Train RÂ²", f"{r2_tr:.3f}")
    c2.metric("Test RÂ²", f"{r2_te:.3f}")
    c3.metric("Test RMSE", f"{rmse_te:.3f}")
    st.caption(f"Test MAE: {mae_te:.3f}")

    # ì˜ˆì¸¡ vs ì‹¤ì œ (ìµœê·¼ êµ¬ê°„)
    st.subheader("ğŸ” ì‹¤ì œ vs ì˜ˆì¸¡ (ìµœê·¼ ê²€ì¦ êµ¬ê°„)")
    compare_df = test_X.copy()
    compare_df["ì‹¤ì œê°’"] = test_y.values
    compare_df["ì˜ˆì¸¡ê°’"] = pred_test
    compare_df = compare_df.assign(ë‚ ì§œ=merged.iloc[-test_size:]["ë‚ ì§œ"].values)[["ë‚ ì§œ", "ì‹¤ì œê°’", "ì˜ˆì¸¡ê°’"]]
    st.dataframe(compare_df.tail(20))
    st.line_chart(compare_df.set_index("ë‚ ì§œ"))

    # í”¼ì²˜ ì¤‘ìš”ë„ (íŠ¸ë¦¬ëª¨ë¸ì¼ ë•Œ)
    if model_name == "RandomForest":
        try:
            # íŒŒì´í”„ ë‚´ë¶€ì—ì„œ í•™ìŠµëœ ëª¨ë¸ ì ‘ê·¼ì„ ìœ„í•´ ì „ì²˜ë¦¬ í›„ í•™ìŠµì„ ë³„ë„ë¡œ ìˆ˜í–‰
            prep = preprocessor.fit(train_X)
            Xtr = prep.transform(train_X)
            rf = RandomForestRegressor(n_estimators=400, random_state=42)
            rf.fit(Xtr, train_y)
            importances = rf.feature_importances_
            imp_df = pd.DataFrame({"feature": feature_cols, "importance": importances}).sort_values("importance", ascending=False)
            st.subheader("ğŸŒŸ í”¼ì²˜ ì¤‘ìš”ë„ (RandomForest)")
            st.dataframe(imp_df.head(20))
        except Exception as e:
            st.info(f"í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

    # =============================
    # ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ (ê°€ìƒ í™˜ê²½ ì…ë ¥)
    # =============================
    st.subheader("ğŸ§ª ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡: í™˜ê²½ ê°’ì„ ì§ì ‘ ì…ë ¥í•˜ì—¬ íƒ€ê¹ƒ ì˜ˆì¸¡")
    with st.expander("í™˜ê²½ ê°’ ì…ë ¥ í¼"):
        inputs = {}
        for c in selected_features:
            # ê¸°ë³¸ê°’: í•™ìŠµêµ¬ê°„ í‰ê· 
            default_val = float(np.nanmean(train_X[c])) if c in train_X else 0.0
            inputs[c] = st.number_input(f"{c}", value=default_val)
        # ë‚ ì§œ íŒŒìƒì¹˜ í•„ìš”
        sim_date = st.date_input("ê°€ì • ë‚ ì§œ", value=pd.to_datetime(merged["ë‚ ì§œ"].iloc[-1]).date())
        sim = {
            "year": sim_date.year,
            "month": sim_date.month,
            "day": sim_date.day,
            "dow": pd.Timestamp(sim_date).dayofweek,
        }
        # ë¡¤ë§ íŠ¹ì„±ì€ ê°„ë‹¨íˆ í˜„ì¬ê°’ìœ¼ë¡œ ëŒ€ì²´(ë³´ìˆ˜ì  ëŒ€ì¹˜)
        for c in selected_features:
            sim[f"{c}_roll3"] = inputs[c]
            sim[f"{c}_roll7"] = inputs[c]
        # ë‹¨ì¼ ìƒ˜í”Œ DataFrame êµ¬ì„±
        sim_row = {**{k: inputs[k] for k in selected_features}, **sim}
        sim_df = pd.DataFrame([sim_row])[feature_cols]
        pred_sim = pipe.predict(sim_df)[0]
        st.success(f"ì˜ˆìƒ {target_col}: {pred_sim:.3f}")

else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í™˜ê²½ ì—‘ì…€ê³¼ ìƒìœ¡/ìˆ˜í™•ëŸ‰ ì—‘ì…€ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

st.caption("Tip: ì˜ˆì¸¡ë ¥ì´ ë‚®ë‹¤ë©´ (1) íƒ€ê¹ƒì„ ì£¼ê°„/ì›”ê°„ ì§‘ê³„ë¡œ ë°”ê¾¸ê±°ë‚˜, (2) ë¡¤ë§ ìœˆë„ìš°ë¥¼ ëŠ˜ë¦¬ê³ , (3) ê³„ì ˆ/í’ˆì¢…/ìƒìœ¡ë‹¨ê³„ ê°™ì€ ë©”íƒ€ì •ë³´ë¥¼ ì¶”ê°€í•´ ë³´ì„¸ìš”.")
